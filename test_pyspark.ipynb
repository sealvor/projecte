{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e230c260",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c5db7371",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8d12b6ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>age</th>\n",
       "      <th>experience</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>haha</td>\n",
       "      <td>11.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bibi</td>\n",
       "      <td>22.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cici</td>\n",
       "      <td>33.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>didi</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>eiei</td>\n",
       "      <td>55.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NaN</td>\n",
       "      <td>66.0</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NaN</td>\n",
       "      <td>77.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   name   age  experience\n",
       "0  haha  11.0         5.0\n",
       "1  bibi  22.0         7.0\n",
       "2  cici  33.0        10.0\n",
       "3  didi   NaN         3.0\n",
       "4  eiei  55.0         NaN\n",
       "5   NaN  66.0        20.0\n",
       "6   NaN  77.0         NaN"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv('example_csv.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "554d8e02",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "99dbd1ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "21/08/23 22:55:29 WARN Utils: Your hostname, tanhongyus-MacBook-Air.local resolves to a loopback address: 127.0.0.1; using 192.168.3.93 instead (on interface en0)\n",
      "21/08/23 22:55:29 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "21/08/23 22:55:30 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "21/08/23 22:55:31 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder.appName('practice').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "53e02cb3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://192.168.3.93:4041\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.1.2</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>practice</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x117866a60>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8c365fce",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_spark = spark.read.csv('example_csv.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dfaa2341",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----+----------+\n",
      "| _c0| _c1|       _c2|\n",
      "+----+----+----------+\n",
      "|name| age|experience|\n",
      "|haha|  11|         5|\n",
      "|bibi|  22|         7|\n",
      "|cici|  33|        10|\n",
      "|didi|null|         3|\n",
      "|eiei|  55|      null|\n",
      "|null|  66|        20|\n",
      "|null|  77|      null|\n",
      "+----+----+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_spark.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "424ce357",
   "metadata": {},
   "source": [
    "read dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e7de68fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----+----------+\n",
      "|name| age|experience|\n",
      "+----+----+----------+\n",
      "|haha|  11|         5|\n",
      "|bibi|  22|         7|\n",
      "|cici|  33|        10|\n",
      "|didi|null|         3|\n",
      "|eiei|  55|      null|\n",
      "|null|  66|        20|\n",
      "|null|  77|      null|\n",
      "+----+----+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark = spark.read.option('header','true').csv('example_csv.csv', inferSchema=True)\n",
    "df_pyspark.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9a7770be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.sql.dataframe.DataFrame"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(df_pyspark)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0bf9453",
   "metadata": {},
   "source": [
    "check schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ee5a9c07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- name: string (nullable = true)\n",
      " |-- age: integer (nullable = true)\n",
      " |-- experience: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "97d3e84c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pyspark = spark.read.csv('example_csv.csv', header=True, inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d995d224",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----+----------+\n",
      "|name| age|experience|\n",
      "+----+----+----------+\n",
      "|haha|  11|         5|\n",
      "|bibi|  22|         7|\n",
      "|cici|  33|        10|\n",
      "|didi|null|         3|\n",
      "|eiei|  55|      null|\n",
      "|null|  66|        20|\n",
      "|null|  77|      null|\n",
      "+----+----+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c177a217",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.sql.dataframe.DataFrame"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(df_pyspark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0d745358",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['name', 'age', 'experience']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pyspark.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "72bc7d06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(name='haha', age=11, experience=5),\n",
       " Row(name='bibi', age=22, experience=7)]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pyspark.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d640c38a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----+\n",
      "|name| age|\n",
      "+----+----+\n",
      "|haha|  11|\n",
      "|bibi|  22|\n",
      "|cici|  33|\n",
      "|didi|null|\n",
      "|eiei|  55|\n",
      "|null|  66|\n",
      "|null|  77|\n",
      "+----+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.select(['name','age']).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e185a551",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('name', 'string'), ('age', 'int'), ('experience', 'int')]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pyspark.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "79be5c1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[summary: string, name: string, age: string, experience: string]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pyspark.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "410bf49b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----+-----------------+-----------------+\n",
      "|summary|name|              age|       experience|\n",
      "+-------+----+-----------------+-----------------+\n",
      "|  count|   5|                6|                5|\n",
      "|   mean|null|             44.0|              9.0|\n",
      "| stddev|null|26.03075104563831|6.670832032063167|\n",
      "|    min|bibi|               11|                3|\n",
      "|    max|haha|               77|               20|\n",
      "+-------+----+-----------------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.describe().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0f551ed",
   "metadata": {},
   "source": [
    "add columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "63780b53",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pyspark = df_pyspark.withColumn('experience', df_pyspark['age']-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a87dd48f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----+----------+\n",
      "|name| age|experience|\n",
      "+----+----+----------+\n",
      "|haha|  11|         5|\n",
      "|bibi|  22|        16|\n",
      "|cici|  33|        27|\n",
      "|didi|null|      null|\n",
      "|eiei|  55|        49|\n",
      "|null|  66|        60|\n",
      "|null|  77|        71|\n",
      "+----+----+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95402d6a",
   "metadata": {},
   "source": [
    "drop columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "17c76217",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----+\n",
      "|name| age|\n",
      "+----+----+\n",
      "|haha|  11|\n",
      "|bibi|  22|\n",
      "|cici|  33|\n",
      "|didi|null|\n",
      "|eiei|  55|\n",
      "|null|  66|\n",
      "|null|  77|\n",
      "+----+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.drop('experience').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69ff32ee",
   "metadata": {},
   "source": [
    "rename colums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "63f96531",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----+----------+\n",
      "|new_name| age|experience|\n",
      "+--------+----+----------+\n",
      "|    haha|  11|         5|\n",
      "|    bibi|  22|        16|\n",
      "|    cici|  33|        27|\n",
      "|    didi|null|      null|\n",
      "|    eiei|  55|        49|\n",
      "|    null|  66|        60|\n",
      "|    null|  77|        71|\n",
      "+--------+----+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.withColumnRenamed('name', 'new_name').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1d61e2b",
   "metadata": {},
   "source": [
    "handle missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "312c5702",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pyspark = spark.read.csv('example_csv.csv', header=True, inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bfbb54c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----+----------+\n",
      "|name| age|experience|\n",
      "+----+----+----------+\n",
      "|haha|  11|         5|\n",
      "|bibi|  22|         7|\n",
      "|cici|  33|        10|\n",
      "|didi|null|         3|\n",
      "|eiei|  55|      null|\n",
      "|null|  66|        20|\n",
      "|null|  77|      null|\n",
      "+----+----+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3591fe52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---+----------+\n",
      "|name|age|experience|\n",
      "+----+---+----------+\n",
      "|haha| 11|         5|\n",
      "|bibi| 22|         7|\n",
      "|cici| 33|        10|\n",
      "+----+---+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.na.drop(how='any').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "42caaebd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----+----------+\n",
      "|name| age|experience|\n",
      "+----+----+----------+\n",
      "|haha|  11|         5|\n",
      "|bibi|  22|         7|\n",
      "|cici|  33|        10|\n",
      "|didi|null|         3|\n",
      "|eiei|  55|      null|\n",
      "|null|  66|        20|\n",
      "|null|  77|      null|\n",
      "+----+----+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.na.drop(how='all').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b492d16",
   "metadata": {},
   "source": [
    "thresholdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "293a4185",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----+----------+\n",
      "|name| age|experience|\n",
      "+----+----+----------+\n",
      "|haha|  11|         5|\n",
      "|bibi|  22|         7|\n",
      "|cici|  33|        10|\n",
      "|didi|null|         3|\n",
      "|eiei|  55|      null|\n",
      "|null|  66|        20|\n",
      "+----+----+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.na.drop(how='all', thresh=2).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "acf9b72f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----+----------+\n",
      "|name| age|experience|\n",
      "+----+----+----------+\n",
      "|haha|  11|         5|\n",
      "|bibi|  22|         7|\n",
      "|cici|  33|        10|\n",
      "|didi|null|         3|\n",
      "|eiei|  55|      null|\n",
      "|null|  66|        20|\n",
      "|null|  77|      null|\n",
      "+----+----+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.na.drop(how='all', thresh=1).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "912f9ce1",
   "metadata": {},
   "source": [
    "subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ddee329b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----+----------+\n",
      "|name| age|experience|\n",
      "+----+----+----------+\n",
      "|haha|  11|         5|\n",
      "|bibi|  22|         7|\n",
      "|cici|  33|        10|\n",
      "|didi|null|         3|\n",
      "|null|  66|        20|\n",
      "+----+----+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.na.drop(how='any', subset=['experience']).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5660f59d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----+----------+\n",
      "|name| age|experience|\n",
      "+----+----+----------+\n",
      "|haha|  11|         5|\n",
      "|bibi|  22|         7|\n",
      "|cici|  33|        10|\n",
      "|didi|null|         3|\n",
      "|eiei|  55|      null|\n",
      "+----+----+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.na.drop(how='any', subset=['name']).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a51c8d3",
   "metadata": {},
   "source": [
    "filling missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a03ef604",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('name', 'string'), ('age', 'int'), ('experience', 'int')]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pyspark.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4a1d7792",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import Imputer\n",
    "\n",
    "imputer = Imputer(\n",
    "    inputCols = ['age','experience'],\n",
    "    outputCols = [\"{}_imputed\".format(c) for c in ['age','experience']]\n",
    ").setStrategy(\"mean\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7517b33b",
   "metadata": {},
   "source": [
    "add imputation cols to df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0f1b8894",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----+----------+-----------+------------------+\n",
      "|name| age|experience|age_imputed|experience_imputed|\n",
      "+----+----+----------+-----------+------------------+\n",
      "|haha|  11|         5|         11|                 5|\n",
      "|bibi|  22|         7|         22|                 7|\n",
      "|cici|  33|        10|         33|                10|\n",
      "|didi|null|         3|         44|                 3|\n",
      "|eiei|  55|      null|         55|                 9|\n",
      "|null|  66|        20|         66|                20|\n",
      "|null|  77|      null|         77|                 9|\n",
      "+----+----+----------+-----------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "imputer.fit(df_pyspark).transform(df_pyspark).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a216780f",
   "metadata": {},
   "source": [
    "filter operation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "95fff2f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---+----------+\n",
      "|name|age|experience|\n",
      "+----+---+----------+\n",
      "|cici| 11|         5|\n",
      "|didi| 22|         7|\n",
      "|cici| 33|        10|\n",
      "|didi| 44|         3|\n",
      "|eiei| 55|         7|\n",
      "|efef| 66|        20|\n",
      "|efef| 77|        30|\n",
      "+----+---+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark = spark.read.csv(\"example_csv2.csv\", header=True, inferSchema=True)\n",
    "df_pyspark.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a4fc830",
   "metadata": {},
   "source": [
    "filter options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "1c917364",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---+\n",
      "|name|age|\n",
      "+----+---+\n",
      "|cici| 11|\n",
      "|didi| 22|\n",
      "+----+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.filter('age<33').select('name','age').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "0991e8aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---+----------+\n",
      "|name|age|experience|\n",
      "+----+---+----------+\n",
      "|cici| 11|         5|\n",
      "|didi| 22|         7|\n",
      "|cici| 33|        10|\n",
      "|didi| 44|         3|\n",
      "|eiei| 55|         7|\n",
      "+----+---+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.filter(df_pyspark['experience']<=10).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "97257e62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---+----------+\n",
      "|name|age|experience|\n",
      "+----+---+----------+\n",
      "|efef| 66|        20|\n",
      "|efef| 77|        30|\n",
      "+----+---+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.filter(~(df_pyspark['experience']<=10)).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fe40b1c",
   "metadata": {},
   "source": [
    "GroupBy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "dd0a5174",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- name: string (nullable = true)\n",
      " |-- age: integer (nullable = true)\n",
      " |-- experience: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "832dbe99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---+----------+\n",
      "|name|age|experience|\n",
      "+----+---+----------+\n",
      "|cici| 11|         5|\n",
      "|didi| 22|         7|\n",
      "|cici| 33|        10|\n",
      "|didi| 44|         3|\n",
      "|eiei| 55|         7|\n",
      "|efef| 66|        20|\n",
      "|efef| 77|        30|\n",
      "+----+---+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "10f139f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+--------+---------------+\n",
      "|name|sum(age)|sum(experience)|\n",
      "+----+--------+---------------+\n",
      "|didi|      66|             10|\n",
      "|cici|      44|             15|\n",
      "|efef|     143|             50|\n",
      "|eiei|      55|              7|\n",
      "+----+--------+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.groupby('name').sum().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "2366cabb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|sum(age)|\n",
      "+--------+\n",
      "|     308|\n",
      "+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.agg({'age':'sum'}).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "e752d6b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+--------+---------------+\n",
      "|name|max(age)|max(experience)|\n",
      "+----+--------+---------------+\n",
      "|didi|      44|              7|\n",
      "|cici|      33|             10|\n",
      "|efef|      77|             30|\n",
      "|eiei|      55|              7|\n",
      "+----+--------+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.groupby('name').max().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00a25583",
   "metadata": {},
   "source": [
    "Example of ml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "a27d9b17",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pyspark = spark.read.csv(\"Iris.csv\", header=True, inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "035c054b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------------+------------+-------------+------------+-----------+\n",
      "| Id|SepalLengthCm|SepalWidthCm|PetalLengthCm|PetalWidthCm|    Species|\n",
      "+---+-------------+------------+-------------+------------+-----------+\n",
      "|  1|          5.1|         3.5|          1.4|         0.2|Iris-setosa|\n",
      "|  2|          4.9|         3.0|          1.4|         0.2|Iris-setosa|\n",
      "|  3|          4.7|         3.2|          1.3|         0.2|Iris-setosa|\n",
      "+---+-------------+------------+-------------+------------+-----------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "4d25c2f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Id',\n",
       " 'SepalLengthCm',\n",
       " 'SepalWidthCm',\n",
       " 'PetalLengthCm',\n",
       " 'PetalWidthCm',\n",
       " 'Species']"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pyspark.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "6681226f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import VectorAssembler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "4acba289",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_assembler = VectorAssembler(inputCols=['SepalLengthCm','SepalWidthCm','PetalLengthCm','PetalWidthCm'],\n",
    "                                    outputCol='Independent Features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "82076e96",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = feature_assembler.transform(df_pyspark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "93522245",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------------+------------+-------------+------------+-----------+--------------------+\n",
      "| Id|SepalLengthCm|SepalWidthCm|PetalLengthCm|PetalWidthCm|    Species|Independent Features|\n",
      "+---+-------------+------------+-------------+------------+-----------+--------------------+\n",
      "|  1|          5.1|         3.5|          1.4|         0.2|Iris-setosa|   [5.1,3.5,1.4,0.2]|\n",
      "|  2|          4.9|         3.0|          1.4|         0.2|Iris-setosa|   [4.9,3.0,1.4,0.2]|\n",
      "|  3|          4.7|         3.2|          1.3|         0.2|Iris-setosa|   [4.7,3.2,1.3,0.2]|\n",
      "+---+-------------+------------+-------------+------------+-----------+--------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "output.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "a75b7158",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Id',\n",
       " 'SepalLengthCm',\n",
       " 'SepalWidthCm',\n",
       " 'PetalLengthCm',\n",
       " 'PetalWidthCm',\n",
       " 'Species',\n",
       " 'Independent Features']"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "c83d583c",
   "metadata": {},
   "outputs": [],
   "source": [
    "finalized_data = output.select('Species', \"Independent Features\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "5d78e646",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------------------+\n",
      "|    Species|Independent Features|\n",
      "+-----------+--------------------+\n",
      "|Iris-setosa|   [5.1,3.5,1.4,0.2]|\n",
      "|Iris-setosa|   [4.9,3.0,1.4,0.2]|\n",
      "|Iris-setosa|   [4.7,3.2,1.3,0.2]|\n",
      "+-----------+--------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "finalized_data.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "5968f03a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import StringIndexer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "146cfd63",
   "metadata": {},
   "outputs": [],
   "source": [
    "labelindexer = StringIndexer(inputCol=\"Species\", outputCol=\"indexedLabel\").fit(finalized_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "82b743bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "finalized_data = labelindexer.transform(finalized_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "8204c97e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------------------+------------+\n",
      "|    Species|Independent Features|indexedLabel|\n",
      "+-----------+--------------------+------------+\n",
      "|Iris-setosa|   [5.1,3.5,1.4,0.2]|         0.0|\n",
      "|Iris-setosa|   [4.9,3.0,1.4,0.2]|         0.0|\n",
      "|Iris-setosa|   [4.7,3.2,1.3,0.2]|         0.0|\n",
      "+-----------+--------------------+------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "finalized_data.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "18bf5e68",
   "metadata": {},
   "outputs": [],
   "source": [
    "finalized_data = finalized_data.select(\"Independent Features\", 'indexedLabel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "78ebc43a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------------+\n",
      "|Independent Features|indexedLabel|\n",
      "+--------------------+------------+\n",
      "|   [5.1,3.5,1.4,0.2]|         0.0|\n",
      "|   [4.9,3.0,1.4,0.2]|         0.0|\n",
      "|   [4.7,3.2,1.3,0.2]|         0.0|\n",
      "+--------------------+------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "finalized_data.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "50120916",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.regression import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "9d4c5f06",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data = finalized_data.randomSplit([0.75, 0.25])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "7e6328e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor = LinearRegression(featuresCol=\"Independent Features\", labelCol=\"indexedLabel\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "054aca89",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "21/08/23 23:40:00 WARN Instrumentation: [99dd560a] regParam is zero, which might cause numerical instability and overfitting.\n",
      "21/08/23 23:40:00 WARN BLAS: Failed to load implementation from: com.github.fommil.netlib.NativeSystemBLAS\n",
      "21/08/23 23:40:00 WARN BLAS: Failed to load implementation from: com.github.fommil.netlib.NativeRefBLAS\n",
      "21/08/23 23:40:01 WARN LAPACK: Failed to load implementation from: com.github.fommil.netlib.NativeSystemLAPACK\n",
      "21/08/23 23:40:01 WARN LAPACK: Failed to load implementation from: com.github.fommil.netlib.NativeRefLAPACK\n"
     ]
    }
   ],
   "source": [
    "regressor = regressor.fit(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "3f31fc93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DenseVector([-0.1395, -0.0451, 0.2263, 0.6376])"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regressor.coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "01fcef14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3338288578967564"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regressor.intercept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "6e9d7e76",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_results = regressor.evaluate(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "811f0fb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------------+--------------------+\n",
      "|Independent Features|indexedLabel|          prediction|\n",
      "+--------------------+------------+--------------------+\n",
      "|   [4.4,3.2,1.3,0.2]|         0.0|-0.00270983598473...|\n",
      "|   [4.9,3.0,1.4,0.2]|         0.0|-0.04083751604703589|\n",
      "|   [5.0,3.2,1.2,0.2]|         0.0|-0.10906280202816832|\n",
      "|   [5.0,3.4,1.5,0.2]|         0.0|-0.05019413360865499|\n",
      "|   [5.0,3.6,1.4,0.2]|         0.0|-0.08183729420437447|\n",
      "|   [5.1,3.3,1.7,0.5]|         0.0| 0.17690198405860735|\n",
      "|   [5.1,3.8,1.5,0.3]|         0.0|-0.01841645188398...|\n",
      "|   [5.1,3.8,1.6,0.2]|         0.0|-0.05955075117027...|\n",
      "|   [5.2,3.5,1.5,0.2]|         0.0| -0.0826100715428203|\n",
      "|   [5.5,2.3,4.0,1.3]|         1.0|  1.1967023974001207|\n",
      "|   [5.5,2.4,3.7,1.0]|         1.0|  0.9330241543474453|\n",
      "|   [5.5,2.4,3.8,1.1]|         1.0|   1.019414368141352|\n",
      "|   [5.5,2.5,4.0,1.3]|         1.0|  1.1876871940582094|\n",
      "|   [5.5,3.5,1.3,0.2]|         0.0|-0.16972849044525107|\n",
      "|   [5.5,4.2,1.4,0.2]|         0.0|-0.17865374488813246|\n",
      "+--------------------+------------+--------------------+\n",
      "only showing top 15 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pred_results.predictions.show(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "0ab6f47f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.1712567301281799, 0.04900276633711635)"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_results.meanAbsoluteError, pred_results.meanSquaredError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "004ef41a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63efe8f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32be3a7b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdcccc26",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fc6efeb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e9a1c1a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b73d9608",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85dca4ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7775b39",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
